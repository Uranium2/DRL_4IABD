{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "n= 5\n",
    "m = 5\n",
    "num_states = n * m  # 25 cases\n",
    "\n",
    "\n",
    "S = np.arange(num_states)\n",
    "A = np.array([0, 1, 2, 3])  # 0: left, 1 : right, 2: top, 3: bot\n",
    "T = np.array([2, 11, 24])  # Terminal State ( position)\n",
    "P = np.zeros((len(S), len(A), len(S), 2))\n",
    "\n",
    "for x in range(n * m):\n",
    "    if (x + 1) % n != 0:  # Droite\n",
    "        P[x, 1, x + 1, 0] = 1.0\n",
    "    if x % n != 0:  # Gauche\n",
    "        P[x, 0, x - 1, 0] = 1.0\n",
    "    if x >= n:  # Top\n",
    "        P[x, 2, x - n, 0] = 1.0\n",
    "    if x < n * m - n:  # Bot\n",
    "        P[x, 3, x + n, 0] = 1.0\n",
    "print(S)\n",
    "        \n",
    "# rewards\n",
    "\n",
    "P[1, 1, 2, 1] = -1\n",
    "P[3, 0, 2, 1] = -1\n",
    "P[7, 2, 2, 1] = -1\n",
    "\n",
    "P[6, 3, 11, 1] = -1\n",
    "P[10, 1, 11, 1] = -1\n",
    "P[12, 0, 11, 1] = -1\n",
    "P[16, 2, 11, 1] = -1\n",
    "\n",
    "# P[13, 3, 18, 1] = -1\n",
    "# P[17, 1, 11, 1] = -1\n",
    "# P[19, 0, 18, 1] = -1\n",
    "# P[23, 2, 18, 1] = -1\n",
    "\n",
    "P[23, 1, 24, 1] = 1\n",
    "P[19, 3, 24, 1] = 1\n",
    "\n",
    "def reset() -> int:\n",
    "    return n * m  // 2\n",
    "\n",
    "\n",
    "def is_terminal(state: int) -> bool:\n",
    "    return state in T\n",
    "\n",
    "\n",
    "def step(state: int, a: int) -> (int, float, bool):\n",
    "    assert (state not in T)\n",
    "    s_p = np.random.choice(S, p=P[state, a, :, 0]) # trouve ta position d'arrivée\n",
    "    r = P[state, a, s_p, 1] # recupere reward\n",
    "    return s_p, r, (s_p in T) # position, reward, si terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_policy_evaluation(\n",
    "        S: np.ndarray,\n",
    "        A: np.ndarray,\n",
    "        P: np.ndarray,\n",
    "        T: np.ndarray,\n",
    "        Pi: np.ndarray,\n",
    "        gamma: float = 0.99,\n",
    "        theta: float = 0.0001, # accuracy\n",
    "        V: np.ndarray = None\n",
    ") -> np.ndarray:\n",
    "    assert 0 <= gamma <= 1\n",
    "    assert theta > 0\n",
    "    if V is None:\n",
    "        V = np.random.random((S.shape[0],))\n",
    "        V[T] = 0.0\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in S:\n",
    "            v_temp = V[s]\n",
    "            tmp_sum = 0\n",
    "            for a in A:\n",
    "                for s_p in S: # proba x faisabilité x (reward + longterme x Value s')\n",
    "                    tmp_sum += Pi[s, a] * P[s, a, s_p, 0] * (\n",
    "                            P[s, a, s_p, 1] + gamma * V[s_p]\n",
    "                    )\n",
    "            V[s] = tmp_sum\n",
    "            delta = np.maximum(delta, np.abs(tmp_sum - v_temp))\n",
    "        if delta < theta:\n",
    "            break\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabular_uniform_random_policy(space_size: int, action_size: int):\n",
    "    return np.ones((space_size, action_size)) / action_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.11963510513305664 seconds ---\n",
      "-0.2946619 -0.7075249 -0.561987 -0.5697107 -0.1915121 \n",
      "-0.4831402 -0.9920751 -0.9935427 -0.5383428 -0.2041058 \n",
      "-0.6654835 -0.8142405 -0.9119507 -0.4078543 -0.0948449 \n",
      "-0.3814643 -0.7204939 -0.4590321 -0.1028326 0.2287259 \n",
      "-0.1553739 -0.2463394 -0.1194729 0.2226305 0.1117107 "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "Pi = tabular_uniform_random_policy(S.shape[0], A.shape[0])\n",
    "\n",
    "V = iterative_policy_evaluation(S, A, P, T, Pi)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "for i in range(n * m):\n",
    "    if i % 5 == 0 and i != 0:\n",
    "        print(\"\")\n",
    "    print(round(V[i], 7), end=\" \")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.29476562 -0.29476562 -0.29476562 -0.29476562 -0.29476562 \n",
      "-0.99230396 -0.99230396 -0.99230396 -0.99230396 -0.99230396 \n",
      "-0.91217499 -0.91217499 -0.91217499 -0.91217499 -0.91217499 \n",
      "-0.10295628 -0.10295628 -0.10295628 -0.10295628 -0.10295628 \n",
      "0.11168043 0.11168043 0.11168043 0.11168043 0.11168043 \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 0.0, False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step(21, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " S.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26714842, 0.21421822, 0.32541552, 0.37578865, 0.41400078,\n",
       "       0.55934601, 0.92963451, 0.1605333 , 0.02212195, 0.96035614,\n",
       "       0.16957847, 0.66020583, 0.27217966, 0.08257213, 0.613618  ,\n",
       "       0.37209803, 0.19578446, 0.48936394, 0.77395945, 0.47284574,\n",
       "       0.37662938, 0.56220103, 0.24513202, 0.15666688, 0.21003998])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = np.random.random((S.shape[0],))\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_grid_world(w, h, reward_list, terminal):\n",
    "    num_states = w * h\n",
    "\n",
    "    S = np.arange(num_states)\n",
    "    A = np.array([0, 1, 2, 3])  # 0: left, 1 : right, 2: top, 3: bot\n",
    "    T = np.array(terminal)  # Terminal State ( position)\n",
    "    P = np.zeros((len(S), len(A), len(S), 2))\n",
    "\n",
    "    for x in range(w * h):\n",
    "        if (x + 1) % w != 0:  # Droite\n",
    "            P[x, 1, x + 1, 0] = 1.0\n",
    "        if x % w != 0:  # Gauche\n",
    "            P[x, 0, x - 1, 0] = 1.0\n",
    "        if x >= w:  # Top\n",
    "            P[x, 2, x - w, 0] = 1.0\n",
    "        if x < w * h - w:  # Bot\n",
    "            P[x, 3, x + w, 0] = 1.0\n",
    "\n",
    "#     for r in reward_list:\n",
    "#         set_reward(P, r, w, h)\n",
    "    P[1, 1, 2, 1] = -1\n",
    "    P[3, 0, 2, 1] = -1\n",
    "    P[7, 2, 2, 1] = -1\n",
    "\n",
    "    P[6, 3, 11, 1] = -1\n",
    "    P[10, 1, 11, 1] = -1\n",
    "    P[12, 0, 11, 1] = -1\n",
    "    P[16, 2, 11, 1] = -1\n",
    "\n",
    "    # P[13, 3, 18, 1] = -1\n",
    "    # P[17, 1, 11, 1] = -1\n",
    "    # P[19, 0, 18, 1] = -1\n",
    "    # P[23, 2, 18, 1] = -1\n",
    "\n",
    "    P[23, 1, 24, 1] = 1\n",
    "    P[19, 3, 24, 1] = 1\n",
    "\n",
    "    return S, A, T, P\n",
    "\n",
    "def set_reward(P, reward_tuple, n, m):\n",
    "    if (reward_tuple[0] + 1) % n != 0: # case de Droite\n",
    "        P[reward_tuple[0] + 1, 0,reward_tuple[0], 1] = reward_tuple[1]\n",
    "\n",
    "    if (reward_tuple[0] - 1) % n != 0: # case de Gauche\n",
    "        P[reward_tuple[0] - 1, 1, reward_tuple[0], 1] = reward_tuple[1]\n",
    "\n",
    "    if reward_tuple[0] - n >= n: #  case du top\n",
    "        P[reward_tuple[0] - n, 3, reward_tuple[0], 1] = reward_tuple[1]\n",
    "\n",
    "    if reward_tuple[0] + n < n * m - n: # case du bot\n",
    "        P[reward_tuple[0] + n, 2, reward_tuple[0], 1] = reward_tuple[1]\n",
    "\n",
    "def tabular_uniform_random_policy(space_size: int, action_size: int):\n",
    "    return np.ones((space_size, action_size))\n",
    "\n",
    "def reset(w, h) -> int:\n",
    "    return w * h // 2\n",
    "\n",
    "def is_terminal(state: int, T) -> bool:\n",
    "    return state in T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w = 5\n",
    "h = 5\n",
    "rewards = ((24, 1),\n",
    "           (2, -1),\n",
    "           (11, -1))\n",
    "\n",
    "terminal = [2, 11, 24]\n",
    "\n",
    "S, A, T, P = create_grid_world(w, h, rewards, terminal)\n",
    "Pi = tabular_uniform_random_policy(S.shape[0], A.shape[0])\n",
    "\n",
    "V = iterative_policy_evaluation(S, A, P, T, Pi)\n",
    "\n",
    "\n",
    "for i in range(w * h):\n",
    "    if i % 5 == 0 and i != 0:\n",
    "        print(\"\")\n",
    "    print(round(V[i], 7), end=\" \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 5\n",
    "h = 5\n",
    "rewards = ((24, 1),\n",
    "           (2, -1),\n",
    "           (11, -1))\n",
    "\n",
    "terminal = [2, 11, 24]\n",
    "\n",
    "S, A, T, P = create_grid_world(w, h, rewards, terminal)\n",
    "Pi = tabular_uniform_random_policy(S.shape[0], A.shape[0])\n",
    "\n",
    "V = iterative_policy_evaluation(S, A, P, T, Pi)\n",
    "\n",
    "\n",
    "for i in range(w * h):\n",
    "    if i % 5 == 0 and i != 0:\n",
    "        print(\"\")\n",
    "    print(round(V[i], 7), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}